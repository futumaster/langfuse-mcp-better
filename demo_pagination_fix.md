# è‡ªåŠ¨åˆ†é¡µåŠŸèƒ½ - é—®é¢˜ä¿®å¤æ€»ç»“

## é—®é¢˜æè¿°

ç”¨æˆ·åœ¨ä½¿ç”¨ `fetch_llm_training_data` æ—¶é‡åˆ° LangFuse API é™åˆ¶é”™è¯¯ï¼š

```
Error: status_code: 400, body: {'message': 'Invalid request data', 
'error': [{'code': 'too_big', 'maximum': 100, 'path': ['limit'], 
'message': 'Too big: expected number to be <=100'}]}
```

## é—®é¢˜åˆ†æ

- **æ ¹æœ¬åŸå› **: LangFuse API é™åˆ¶å•æ¬¡è¯·æ±‚æœ€å¤šè¿”å› 100 æ¡è®°å½•
- **è®¾è®¡ç¼ºé™·**: ä¹‹å‰ç›´æ¥å°†ç”¨æˆ·çš„ `limit` å‚æ•°ä¼ é€’ç»™ APIï¼Œå¯¼è‡´è¶…è¿‡ 100 æ—¶æŠ¥é”™
- **ç”¨æˆ·æœŸæœ›**: ä½œä¸ºè®­ç»ƒæ•°æ®æå–å·¥å…·ï¼Œåº”è¯¥èƒ½å¤Ÿè·å–å¤§è§„æ¨¡æ•°æ®ï¼ˆ1000ã€10000 ç­‰ï¼‰

## è§£å†³æ–¹æ¡ˆ

### 1. å®ç°è‡ªåŠ¨åˆ†é¡µ

åœ¨ MCP å†…éƒ¨å®ç°è‡ªåŠ¨åˆ†é¡µé€»è¾‘ï¼Œå¯¹ç”¨æˆ·å®Œå…¨é€æ˜ï¼š

```python
# ç”¨æˆ·å¯ä»¥è¯·æ±‚ä»»æ„æ•°é‡çš„æ•°æ®
fetch_llm_training_data(
    age=10080,
    ls_model_name="Qwen3_235B_A22B_Instruct_2507",
    limit=5000,  # âœ… ç°åœ¨å¯ä»¥æ˜¯ä»»æ„å¤§å°ï¼
    output_format="openai"
)

# MCP å†…éƒ¨ä¼šè‡ªåŠ¨ï¼š
# - å°†è¯·æ±‚æ‹†åˆ†æˆå¤šä¸ª 100 æ¡çš„æ‰¹æ¬¡
# - è‡ªåŠ¨è°ƒç”¨ API å¤šæ¬¡ï¼ˆ50 æ¬¡é¡µé¢ï¼‰
# - èšåˆæ‰€æœ‰ç»“æœ
# - è¿”å›å®Œæ•´çš„ 5000 æ¡æ•°æ®
```

### 2. å…³é”®å®ç°ç»†èŠ‚

#### ç§»é™¤ `page` å‚æ•°
```python
# âŒ æ—§ç‰ˆæœ¬ - éœ€è¦ç”¨æˆ·æ‰‹åŠ¨åˆ†é¡µ
fetch_llm_training_data(..., limit=100, page=1)
fetch_llm_training_data(..., limit=100, page=2)
fetch_llm_training_data(..., limit=100, page=3)

# âœ… æ–°ç‰ˆæœ¬ - è‡ªåŠ¨å¤„ç†
fetch_llm_training_data(..., limit=1000)  # è‡ªåŠ¨è·å– 1000 æ¡
```

#### é»˜è®¤ limit è°ƒæ•´
```python
# ä» 100 æ”¹ä¸º 1000ï¼Œæ›´é€‚åˆè®­ç»ƒæ•°æ®åœºæ™¯
limit: int = Field(
    1000,  # æ–°é»˜è®¤å€¼
    description="Maximum number of training samples to return. Can be any size - pagination is handled automatically."
)
```

#### å†…éƒ¨åˆ†é¡µå¾ªç¯
```python
API_BATCH_SIZE = 100  # LangFuse API é™åˆ¶
all_filtered_observations = []
current_page = 1

while len(all_filtered_observations) < limit:
    # æ¯æ¬¡è·å– 100 æ¡
    observation_items, pagination = _list_observations(
        state.langfuse_client,
        limit=API_BATCH_SIZE,
        page=current_page,
        ...
    )
    
    # åº”ç”¨è¿‡æ»¤å™¨
    batch_filtered = filter_observations(observation_items, filters)
    all_filtered_observations.extend(batch_filtered)
    
    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
    if pagination.get("next_page") is None:
        break
    
    current_page += 1

# è¿”å›ç²¾ç¡®çš„ limit æ•°é‡
return all_filtered_observations[:limit]
```

### 3. è¿”å›çš„ Metadata

æ–°å¢äº†é€æ˜åº¦ä¿¡æ¯ï¼š

```json
{
  "data": [...],
  "metadata": {
    "item_count": 500,
    "output_format": "openai",
    "pages_fetched": 5,              // âœ… æ–°å¢ï¼šè·å–äº†å¤šå°‘é¡µ
    "total_raw_observations": 500,  // âœ… æ–°å¢ï¼šæ€»å…±ä» API è·å–çš„åŸå§‹æ•°æ®é‡
    "filters": {
      "langgraph_node": null,
      "agent_name": null,
      "ls_model_name": "Qwen3_235B_A22B_Instruct_2507"
    }
  }
}
```

## ä¼˜åŠ¿

### âœ… ç”¨æˆ·ä½“éªŒ
- **ç®€å•**: ç”¨æˆ·åªéœ€æŒ‡å®šéœ€è¦çš„æ•°æ®é‡ï¼Œæ— éœ€å…³å¿ƒåˆ†é¡µ
- **çµæ´»**: æ”¯æŒä»»æ„å¤§å°çš„ limitï¼ˆ10ã€100ã€1000ã€10000 ç­‰ï¼‰
- **é€æ˜**: metadata æ˜¾ç¤ºå®é™…è·å–çš„é¡µæ•°ï¼Œä¾¿äºäº†è§£æ•°æ®æ¥æº

### âœ… æŠ€æœ¯å®ç°
- **å°è£…**: å®Œå…¨å°è£… LangFuse API é™åˆ¶
- **æ•ˆç‡**: æ™ºèƒ½åœæ­¢ï¼ˆè¾¾åˆ° limit æˆ–æ— æ›´å¤šæ•°æ®æ—¶ï¼‰
- **å¥å£®**: å¤„ç†è¾¹ç•Œæƒ…å†µï¼ˆæ•°æ®ä¸è¶³ã€è¿‡æ»¤åä¸ºç©ºç­‰ï¼‰

### âœ… æ€§èƒ½è€ƒè™‘
- ä½¿ç”¨æœ€å¤§æ‰¹æ¬¡å¤§å°ï¼ˆ100ï¼‰æé«˜æ•ˆç‡
- åœ¨è¾¾åˆ°ç”¨æˆ·è¯·æ±‚çš„æ•°é‡åç«‹å³åœæ­¢
- å…ˆè¿‡æ»¤å†èšåˆï¼Œå‡å°‘å†…å­˜ä½¿ç”¨

## ä½¿ç”¨ç¤ºä¾‹

### å°è§„æ¨¡æ•°æ®æå–
```python
# åªéœ€è¦ 50 æ¡æ ·æœ¬
fetch_llm_training_data(
    age=1440,
    agent_name="supervisor",
    limit=50,
    output_format="openai"
)
# åªä¼šè°ƒç”¨ 1 æ¬¡ API (pages_fetched: 1)
```

### ä¸­ç­‰è§„æ¨¡æ•°æ®æå–
```python
# éœ€è¦ 500 æ¡æ ·æœ¬
fetch_llm_training_data(
    age=10080,
    langgraph_node="reasoning_node",
    limit=500,
    output_format="generic"
)
# è‡ªåŠ¨è°ƒç”¨ 5 æ¬¡ API (pages_fetched: 5)
```

### å¤§è§„æ¨¡æ•°æ®æå–
```python
# éœ€è¦ 10000 æ¡æ ·æœ¬ç”¨äºè®­ç»ƒ
fetch_llm_training_data(
    age=43200,  # 30 days
    ls_model_name="gpt-4-turbo",
    limit=10000,
    output_format="openai"
)
# è‡ªåŠ¨è°ƒç”¨æœ€å¤š 100 æ¬¡ API (pages_fetched: <= 100)
# å¦‚æœå®é™…æ•°æ®ä¸è¶³ 10000 æ¡ï¼Œè¿”å›æ‰€æœ‰å¯ç”¨æ•°æ®
```

### ä½¿ç”¨é»˜è®¤å€¼
```python
# ä¸æŒ‡å®š limitï¼Œä½¿ç”¨é»˜è®¤çš„ 1000
fetch_llm_training_data(
    age=10080,
    agent_name="worker",
    output_format="generic"
)
# è‡ªåŠ¨è·å–æœ€å¤š 1000 æ¡ (pages_fetched: <= 10)
```

## æµ‹è¯•ç»“æœ

### âœ… å•å…ƒæµ‹è¯•
- æ‰€æœ‰ 23 ä¸ªæµ‹è¯•é€šè¿‡
- fetch_llm_training_data ç›¸å…³çš„ 5 ä¸ªæµ‹è¯•å…¨éƒ¨é€šè¿‡

### âœ… å…¼å®¹æ€§
- ä¿æŒäº†æ‰€æœ‰ç°æœ‰åŠŸèƒ½
- è¾“å‡ºæ ¼å¼æ²¡æœ‰å˜åŒ–
- åªæ˜¯ç§»é™¤äº†æ‰‹åŠ¨ `page` å‚æ•°

## æ–‡æ¡£æ›´æ–°

### Docstring
```python
"""Extract LLM training data from LangGraph nodes for fine-tuning and reinforcement learning.

**Automatic Pagination**: This tool handles LangFuse API limits internally. 
You can request any number of samples (e.g., 1000, 10000) and the tool will 
automatically paginate through the API to collect all requested data. 
No manual pagination required!

Args:
    limit: Maximum number of training samples to return (default: 1000, can be any size)
    ...
"""
```

## æ€»ç»“

è¿™æ¬¡ä¿®å¤å®Œå…¨è§£å†³äº†ç”¨æˆ·çš„ç—›ç‚¹ï¼š

1. **âœ… ç§»é™¤äº† API é™åˆ¶**: ç”¨æˆ·å¯ä»¥è¯·æ±‚ä»»æ„æ•°é‡çš„æ•°æ®
2. **âœ… ç®€åŒ–äº†ä½¿ç”¨**: ä¸éœ€è¦æ‰‹åŠ¨å¤„ç†åˆ†é¡µ
3. **âœ… æé«˜äº†é€æ˜åº¦**: metadata æ˜¾ç¤ºå®é™…çš„æ•°æ®è·å–æƒ…å†µ
4. **âœ… ä¿æŒäº†å…¼å®¹æ€§**: ç°æœ‰åŠŸèƒ½å®Œå…¨ä¸å—å½±å“

**è¿™æ‰æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®­ç»ƒæ•°æ®æå–å·¥å…·åº”æœ‰çš„è®¾è®¡ï¼** ğŸš€

